 {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CausalXray Inference with Attributions\n",
    "\n",
    "This notebook provides an interactive interface for loading trained CausalXray models and performing inference with causal attributions on X-ray images to detect pneumonia and provide interpretable explanations.\n",
    "\n",
    "## Features\n",
    "- Load trained CausalXray models\n",
    "- Perform single image or batch inference\n",
    "- Generate causal attributions using multiple methods\n",
    "- Interactive visualizations\n",
    "- Export results and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union, Any\n",
    "import logging\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Import our custom modules\n",
    "from causalxray.models.causalxray import CausalXrayModel\n",
    "from causalxray.data.transforms import CausalTransforms\n",
    "from causalxray.models.attribution import CausalAttribution\n",
    "from causalxray.utils.visualization import AttributionVisualizer\n",
    "from causalxray.utils.config import load_config, create_default_config\n",
    "\n",
    "# Configure matplotlib for better display\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CausalXray Inference Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalXrayInference:\n",
    "    \"\"\"Inference class for CausalXray models with causal attributions.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        config_path: Optional[str] = None,\n",
    "        device: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the inference engine.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the trained model checkpoint\n",
    "            config_path: Path to the model configuration file\n",
    "            device: Device to run inference on ('cuda', 'cpu', or None for auto)\n",
    "        \"\"\"\n",
    "        self.model_path = Path(model_path)\n",
    "        self.config_path = Path(config_path) if config_path else None\n",
    "        self.device = self._setup_device(device)\n",
    "        \n",
    "        # Load configuration\n",
    "        self.config = self._load_configuration()\n",
    "        \n",
    "        # Initialize components\n",
    "        self.model = None\n",
    "        self.attribution_module = None\n",
    "        self.visualizer = None\n",
    "        \n",
    "        # Setup logging\n",
    "        self._setup_logging()\n",
    "        \n",
    "        # Load model\n",
    "        self._load_model()\n",
    "        \n",
    "        # Setup attribution\n",
    "        self._setup_attribution()\n",
    "    \n",
    "    def _setup_device(self, device: Optional[str]) -> torch.device:\n",
    "        \"\"\"Setup the device for inference.\"\"\"\n",
    "        if device is None:\n",
    "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        device = torch.device(device)\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "            print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "        return device\n",
    "    \n",
    "    def _load_configuration(self) -> Dict[str, Any]:\n",
    "        \"\"\"Load model configuration.\"\"\"\n",
    "        if self.config_path and self.config_path.exists():\n",
    "            config = load_config(str(self.config_path))\n",
    "            print(f\"Loaded configuration from {self.config_path}\")\n",
    "        else:\n",
    "            config = create_default_config()\n",
    "            print(\"Using default configuration\")\n",
    "        \n",
    "        return config\n",
    "    \n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Setup logging configuration.\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger('CausalXrayInference')\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the trained model from checkpoint.\"\"\"\n",
    "        if not self.model_path.exists():\n",
    "            raise FileNotFoundError(f\"Model checkpoint not found: {self.model_path}\")\n",
    "        \n",
    "        print(f\"Loading model from {self.model_path}\")\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(self.model_path, map_location=self.device)\n",
    "        \n",
    "        # Extract configuration from checkpoint if available\n",
    "        if 'config' in checkpoint:\n",
    "            self.config = checkpoint['config']\n",
    "            print(\"Loaded configuration from checkpoint\")\n",
    "        \n",
    "        # Create model\n",
    "        backbone_config = self.config['model']['backbone']\n",
    "        causal_config = self.config['causal']\n",
    "        \n",
    "        self.model = CausalXrayModel(\n",
    "            backbone_config=backbone_config,\n",
    "            causal_config=causal_config\n",
    "        )\n",
    "        \n",
    "        # Load model weights\n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            print(\"Loaded model weights successfully\")\n",
    "        else:\n",
    "            raise ValueError(\"No model_state_dict found in checkpoint\")\n",
    "        \n",
    "        # Move to device\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Print model info\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        print(f\"Model loaded with {total_params:,} parameters\")\n",
    "        \n",
    "        # Print checkpoint info\n",
    "        if 'best_metric' in checkpoint:\n",
    "            print(f\"Best validation metric: {checkpoint['best_metric']:.4f}\")\n",
    "        if 'epoch' in checkpoint:\n",
    "            print(f\"Trained for {checkpoint['epoch']} epochs\")\n",
    "    \n",
    "    def _setup_attribution(self):\n",
    "        \"\"\"Setup causal attribution module.\"\"\"\n",
    "        attribution_config = self.config.get('attribution', {})\n",
    "        \n",
    "        self.attribution_module = CausalAttribution(\n",
    "            model=self.model,\n",
    "            attribution_methods=attribution_config.get('attribution_methods', \n",
    "                                                     ['intervention', 'counterfactual', 'gradcam']),\n",
    "            patch_size=attribution_config.get('patch_size', 16)\n",
    "        )\n",
    "        \n",
    "        self.visualizer = AttributionVisualizer()\n",
    "        print(\"Attribution module initialized\")\n",
    "    \n",
    "    def preprocess_image(self, image_path: str) -> Tuple[torch.Tensor, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Preprocess an image for inference.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the input image\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (preprocessed_tensor, original_image_array)\n",
    "        \"\"\"\n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Convert to RGB if needed\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Keep original for visualization\n",
    "        original_image = np.array(image)\n",
    "        if len(original_image.shape) == 3 and original_image.shape[2] == 3:\n",
    "            original_image = np.mean(original_image, axis=2)  # Convert to grayscale\n",
    "        \n",
    "        # Apply transforms\n",
    "        image_size = tuple(self.config['data']['image_size'])\n",
    "        transforms = CausalTransforms(mode='test', image_size=image_size)\n",
    "        \n",
    "        # Preprocess\n",
    "        image_tensor = transforms(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        return image_tensor, original_image\n",
    "    \n",
    "    def predict(self, image_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Perform prediction on a single image.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the input image\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing prediction results\n",
    "        \"\"\"\n",
    "        print(f\"Analyzing image: {image_path}\")\n",
    "        \n",
    "        # Preprocess image\n",
    "        image_tensor, original_image = self.preprocess_image(image_path)\n",
    "        \n",
    "        # Perform inference\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "            probabilities = outputs['probabilities'].cpu().numpy()[0]\n",
    "            predicted_class = np.argmax(probabilities)\n",
    "        \n",
    "        # Get results\n",
    "        class_names = ['Normal', 'Pneumonia']\n",
    "        predicted_label = class_names[predicted_class]\n",
    "        confidence = probabilities[predicted_class]\n",
    "        \n",
    "        results = {\n",
    "            'image_path': image_path,\n",
    "            'predicted_class': predicted_label,\n",
    "            'predicted_class_id': int(predicted_class),\n",
    "            'confidence': float(confidence),\n",
    "            'probabilities': {\n",
    "                'normal': float(probabilities[0]),\n",
    "                'pneumonia': float(probabilities[1])\n",
    "            },\n",
    "            'original_image': original_image\n",
    "        }\n",
    "        \n",
    "        print(f\"Prediction: {predicted_label} (confidence: {confidence:.4f})\")\n",
    "        print(f\"Probabilities - Normal: {probabilities[0]:.4f}, Pneumonia: {probabilities[1]:.4f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_attributions(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        target_class: Optional[int] = None,\n",
    "        save_visualization: bool = False,\n",
    "        output_dir: Optional[str] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate causal attributions for an image.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the input image\n",
    "            target_class: Target class for attribution (None for predicted class)\n",
    "            save_visualization: Whether to save attribution visualizations\n",
    "            output_dir: Directory to save visualizations\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing attribution results\n",
    "        \"\"\"\n",
    "        print(f\"Generating causal attributions for: {image_path}\")\n",
    "        \n",
    "        # Get prediction first\n",
    "        prediction_results = self.predict(image_path)\n",
    "        \n",
    "        # Preprocess image\n",
    "        image_tensor, original_image = self.preprocess_image(image_path)\n",
    "        \n",
    "        # Generate attributions\n",
    "        with torch.no_grad():\n",
    "            attributions_tensor = self.attribution_module(\n",
    "                image_tensor, \n",
    "                target_class=target_class or prediction_results['predicted_class_id']\n",
    "            )\n",
    "        \n",
    "        # Convert to numpy\n",
    "        attributions_np = {}\n",
    "        for method, attr_tensor in attributions_tensor.items():\n",
    "            if isinstance(attr_tensor, torch.Tensor):\n",
    "                attributions_np[method] = attr_tensor.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Create prediction info for visualization\n",
    "        prediction_info = {\n",
    "            'predicted_class': prediction_results['predicted_class'],\n",
    "            'confidence': prediction_results['confidence'],\n",
    "            'probabilities': prediction_results['probabilities']\n",
    "        }\n",
    "        \n",
    "        # Generate visualizations\n",
    "        if self.visualizer and save_visualization:\n",
    "            # Create output directory\n",
    "            if output_dir is None:\n",
    "                output_dir = Path(image_path).parent / 'attributions'\n",
    "            else:\n",
    "                output_dir = Path(output_dir)\n",
    "            \n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Save comparison visualization\n",
    "            comparison_path = output_dir / f\"{Path(image_path).stem}_attributions.png\"\n",
    "            fig = self.visualizer.visualize_attribution_comparison(\n",
    "                original_image, attributions_np, prediction_info\n",
    "            )\n",
    "            fig.savefig(comparison_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            \n",
    "            # Save statistics visualization\n",
    "            stats_path = output_dir / f\"{Path(image_path).stem}_statistics.png\"\n",
    "            fig = self.visualizer.plot_attribution_statistics(attributions_np)\n",
    "            fig.savefig(stats_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            \n",
    "            print(f\"Attribution visualizations saved to: {output_dir}\")\n",
    "        \n",
    "        # Combine results\n",
    "        results = {\n",
    "            **prediction_results,\n",
    "            'attributions': attributions_np,\n",
    "            'attribution_methods': list(attributions_np.keys())\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_results(self, results: Dict[str, Any]):\n",
    "        \"\"\"Visualize prediction results and attributions.\"\"\"\n",
    "        # Create figure with subplots\n",
    "        n_methods = len(results.get('attributions', {}))\n",
    "        if n_methods > 0:\n",
    "            fig, axes = plt.subplots(2, n_methods + 1, figsize=(4*(n_methods + 1), 8))\n",
    "            \n",
    "            # Original image\n",
    "            axes[0, 0].imshow(results['original_image'], cmap='gray')\n",
    "            axes[0, 0].set_title('Original Image')\n",
    "            axes[0, 0].axis('off')\n",
    "            \n",
    "            # Prediction info\n",
    "            pred_text = f\"Prediction: {results['predicted_class']}\\nConfidence: {results['confidence']:.4f}\"\n",
    "            axes[1, 0].text(0.1, 0.5, pred_text, transform=axes[1, 0].transAxes, \n",
    "                           fontsize=12, verticalalignment='center')\n",
    "            axes[1, 0].set_xlim(0, 1)\n",
    "            axes[1, 0].set_ylim(0, 1)\n",
    "            axes[1, 0].axis('off')\n",
    "            \n",
    "            # Attributions\n",
    "            for i, (method, attribution) in enumerate(results['attributions'].items()):\n",
    "                axes[0, i + 1].imshow(attribution, cmap='Reds')\n",
    "                axes[0, i + 1].set_title(f'{method.title()}')\n",
    "                axes[0, i + 1].axis('off')\n",
    "                \n",
    "                # Statistics\n",
    "                axes[1, i + 1].hist(attribution.flatten(), bins=50, alpha=0.7)\n",
    "                axes[1, i + 1].set_title(f'{method.title()} Distribution')\n",
    "                axes[1, i + 1].set_xlabel('Attribution Value')\n",
    "                axes[1, i + 1].set_ylabel('Frequency')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Just show prediction\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            \n",
    "            ax1.imshow(results['original_image'], cmap='gray')\n",
    "            ax1.set_title('Original Image')\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            # Prediction probabilities\n",
    "            classes = ['Normal', 'Pneumonia']\n",
    "            probs = [results['probabilities']['normal'], results['probabilities']['pneumonia']]\n",
    "            colors = ['green' if results['predicted_class'] == 'Normal' else 'red']\n",
    "            \n",
    "            bars = ax2.bar(classes, probs, color=['lightgreen', 'lightcoral'])\n",
    "            ax2.set_title('Prediction Probabilities')\n",
    "            ax2.set_ylabel('Probability')\n",
    "            ax2.set_ylim(0, 1)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, prob in zip(bars, probs):\n",
    "                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                        f'{prob:.3f}', ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def print_summary(self, results: List[Dict[str, Any]]):\n",
    "        \"\"\"Print a summary of inference results.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"INFERENCE SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Count predictions\n",
    "        predictions = {}\n",
    "        errors = 0\n",
    "        \n",
    "        for result in results:\n",
    "            if 'error' in result:\n",
    "                errors += 1\n",
    "                continue\n",
    "            \n",
    "            pred_class = result['predicted_class']\n",
    "            predictions[pred_class] = predictions.get(pred_class, 0) + 1\n",
    "        \n",
    "        # Print statistics\n",
    "        total_processed = len(results)\n",
    "        successful = total_processed - errors\n",
    "        \n",
    "        print(f\"Total images processed: {total_processed}\")\n",
    "        print(f\"Successful predictions: {successful}\")\n",
    "        print(f\"Errors: {errors}\")\n",
    "        \n",
    "        if predictions:\n",
    "            print(\"\\nPredictions:\")\n",
    "            for class_name, count in predictions.items():\n",
    "                percentage = (count / successful) * 100\n",
    "                print(f\"  {class_name}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Average confidence\n",
    "        if successful > 0:\n",
    "            confidences = [r['confidence'] for r in results if 'confidence' in r]\n",
    "            avg_confidence = np.mean(confidences)\n",
    "            print(f\"\\nAverage confidence: {avg_confidence:.4f}\")\n",
    "        \n",
    "        print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive model loading\n",
    "def load_model_interactive():\n",
    "    \"\"\"Interactive function to load a model.\"\"\"\n",
    "    \n",
    "    # Check for available models\n",
    "    model_paths = []\n",
    "    \n",
    "    # Check common locations\n",
    "    possible_paths = [\n",
    "        'best_model.pth',\n",
    "        '../best_model.pth',\n",
    "        'outputs/best_model.pth',\n",
    "        '../outputs/best_model.pth'\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if Path(path).exists():\n",
    "            model_paths.append(path)\n",
    "    \n",
    "    print(\"Available model files:\")\n",
    "    for i, path in enumerate(model_paths):\n",
    "        print(f\"  {i+1}. {path}\")\n",
    "    \n",
    "    if not model_paths:\n",
    "        print(\"\\nNo model files found in common locations.\")\n",
    "        model_path = input(\"Please enter the path to your model file: \")\n",
    "    else:\n",
    "        choice = input(f\"\\nSelect a model (1-{len(model_paths)}) or enter custom path: \")\n",
    "        try:\n",
    "            choice_idx = int(choice) - 1\n",
    "            if 0 <= choice_idx < len(model_paths):\n",
    "                model_path = model_paths[choice_idx]\n",
    "            else:\n",
    "                model_path = choice\n",
    "        except ValueError:\n",
    "            model_path = choice\n",
    "    \n",
    "    # Device selection\n",
    "    device_choice = input(\"\\nSelect device (cuda/cpu/auto): \").lower()\n",
    "    if device_choice == 'auto':\n",
    "        device = None\n",
    "    elif device_choice in ['cuda', 'cpu']:\n",
    "        device = device_choice\n",
    "    else:\n",
    "        device = None\n",
    "    \n",
    "    try:\n",
    "        inference_engine = CausalXrayInference(\n",
    "            model_path=model_path,\n",
    "            device=device\n",
    "        )\n",
    "        print(\"\\nâœ… Model loaded successfully!\")\n",
    "        return inference_engine\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error loading model: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load the model\n",
    "inference_engine = load_model_interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_single_image(inference_engine, image_path: str, generate_attributions: bool = True):\n",
    "    \"\"\"Analyze a single image with optional attributions.\"\"\"\n",
    "    \n",
    "    if not Path(image_path).exists():\n",
    "        print(f\"âŒ Image file not found: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if generate_attributions:\n",
    "            results = inference_engine.generate_attributions(image_path)\n",
    "        else:\n",
    "            results = inference_engine.predict(image_path)\n",
    "        \n",
    "        # Visualize results\n",
    "        inference_engine.visualize_results(results)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error analyzing image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if inference_engine is not None:\n",
    "    # You can change this path to your image\n",
    "    image_path = \"../xray.jpg\"  # Update this path\n",
    "    \n",
    "    if Path(image_path).exists():\n",
    "        print(f\"Analyzing image: {image_path}\")\n",
    "        results = analyze_single_image(inference_engine, image_path, generate_attributions=True)\n",
    "    else:\n",
    "        print(f\"Image not found: {image_path}\")\n",
    "        print(\"Please update the image_path variable with a valid image path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_analyze_images(inference_engine, image_dir: str, generate_attributions: bool = True):\n",
    "    \"\"\"Analyze multiple images in a directory.\"\"\"\n",
    "    \n",
    "    image_dir_path = Path(image_dir)\n",
    "    if not image_dir_path.exists():\n",
    "        print(f\"âŒ Directory not found: {image_dir}\")\n",
    "        return None\n",
    "    \n",
    "    # Find image files\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
    "    image_paths = [\n",
    "        str(f) for f in image_dir_path.iterdir()\n",
    "        if f.is_file() and f.suffix.lower() in image_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No image files found in {image_dir}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images for batch processing\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        print(f\"\\nProcessing image {i+1}/{len(image_paths)}: {Path(image_path).name}\")\n",
    "        \n",
    "        try:\n",
    "            if generate_attributions:\n",
    "                results = inference_engine.generate_attributions(image_path)\n",
    "            else:\n",
    "                results = inference_engine.predict(image_path)\n",
    "            \n",
    "            all_results.append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {str(e)}\")\n",
    "            all_results.append({\n",
    "                'image_path': image_path,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Print summary\n",
    "    inference_engine.print_summary(all_results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Example usage\n",
    "if inference_engine is not None:\n",
    "    # You can change this to your image directory\n",
    "    image_dir = \"../data/test_images\"  # Update this path\n",
    "    \n",
    "    if Path(image_dir).exists():\n",
    "        print(f\"Batch analyzing images in: {image_dir}\")\n",
    "        results = batch_analyze_images(inference_engine, image_dir, generate_attributions=True)\n",
    "    else:\n",
    "        print(f\"Directory not found: {image_dir}\")\n",
    "        print(\"Please update the image_dir variable with a valid directory path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Analysis Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_interface(inference_engine):\n",
    "    \"\"\"Create an interactive interface for analysis.\"\"\"\n",
    "    \n",
    "    # Create widgets\n",
    "    image_path_widget = widgets.Text(\n",
    "        value='',\n",
    "        description='Image Path:',\n",
    "        placeholder='Enter path to X-ray image'\n",
    "    )\n",
    "    \n",
    "    generate_attributions_widget = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Generate Attributions'\n",
    "    )\n",
    "    \n",
    "    analyze_button = widgets.Button(\n",
    "        description='Analyze Image',\n",
    "        button_style='primary'\n",
    "    )\n",
    "    \n",
    "    output_widget = widgets.Output()\n",
    "    \n",
    "    def on_analyze_click(b):\n",
    "        with output_widget:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            image_path = image_path_widget.value.strip()\n",
    "            if not image_path:\n",
    "                print(\"âŒ Please enter an image path\")\n",
    "                return\n",
    "            \n",
    "            if not Path(image_path).exists():\n",
    "                print(f\"âŒ Image file not found: {image_path}\")\n",
    "                return\n",
    "            \n",
    "            try:\n",
    "                results = analyze_single_image(\n",
    "                    inference_engine, \n",
    "                    image_path, \n",
    "                    generate_attributions_widget.value\n",
    "                )\n",
    "                \n",
    "                if results:\n",
    "                    print(\"âœ… Analysis completed successfully!\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error during analysis: {str(e)}\")\n",
    "    \n",
    "    analyze_button.on_click(on_analyze_click)\n",
    "    \n",
    "    # Display interface\n",
    "    display(HTML(\"<h3>Interactive Image Analysis</h3>\"))\n",
    "    display(widgets.VBox([\n",
    "        image_path_widget,\n",
    "        generate_attributions_widget,\n",
    "        analyze_button,\n",
    "        output_widget\n",
    "    ]))\n",
    "\n",
    "# Create interactive interface\n",
    "if inference_engine is not None:\n",
    "    create_interactive_interface(inference_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(results: List[Dict[str, Any]], output_path: str):\n",
    "    \"\"\"Export analysis results to JSON file.\"\"\"\n",
    "    \n",
    "    # Prepare data for export\n",
    "    export_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        export_result = result.copy()\n",
    "        \n",
    "        # Remove large arrays\n",
    "        if 'original_image' in export_result:\n",
    "            del export_result['original_image']\n",
    "        \n",
    "        # Convert numpy arrays to lists\n",
    "        if 'attributions' in export_result:\n",
    "            export_result['attributions'] = {\n",
    "                k: v.tolist() if isinstance(v, np.ndarray) else v\n",
    "                for k, v in export_result['attributions'].items()\n",
    "            }\n",
    "        \n",
    "        export_data.append(export_result)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Results exported to: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "# export_results(results, 'inference_results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Usage Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage patterns\n",
    "print(\"ðŸ“‹ Usage Examples:\")\n",
    "print(\"\\n1. Single image analysis:\")\n",
    "print(\"   results = analyze_single_image(inference_engine, 'path/to/image.jpg')\")\n",
    "print(\"\\n2. Batch analysis:\")\n",
    "print(\"   results = batch_analyze_images(inference_engine, 'path/to/image/directory')\")\n",
    "print(\"\\n3. Export results:\")\n",
    "print(\"   export_results(results, 'output.json')\")\n",
    "print(\"\\n4. Direct model usage:\")\n",
    "print(\"   results = inference_engine.predict('path/to/image.jpg')\")\n",
    "print(\"   results = inference_engine.generate_attributions('path/to/image.jpg')\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Features:\")\n",
    "print(\"â€¢ Load trained CausalXray models\")\n",
    "print(\"â€¢ Single image and batch analysis\")\n",
    "print(\"â€¢ Multiple attribution methods (intervention, counterfactual, GradCAM)\")\n",
    "print(\"â€¢ Interactive visualizations\")\n",
    "print(\"â€¢ Export results to JSON\")\n",
    "print(\"â€¢ Support for both CPU and GPU inference\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}